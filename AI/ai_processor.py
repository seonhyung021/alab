import base64
import requests
import os
import re
import json
import numpy as np
import matplotlib.pyplot as plt
from openai import OpenAI
from AI.template_matcher import match_template  # í…œí”Œë¦¿ ë§¤ì¹­ í•¨ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
from dotenv import load_dotenv

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY") or "GPTKEY"
MATHPIX_APP_ID = os.getenv("MATHPIX_APP_ID") or "MATHPIXID"
MATHPIX_APP_KEY = os.getenv("MATHPIX_APP_KEY") or "MATHPIXKEY"

client = OpenAI(api_key=OPENAI_API_KEY)

def process_image(image_path: str, grade: str) -> str:
    with open(image_path, "rb") as image_file:
        img_base64 = base64.b64encode(image_file.read()).decode()

    ocr_response = requests.post("https://api.mathpix.com/v3/text", json={
        "src": f"data:image/jpeg;base64,{img_base64}",
        "formats": ["text"],
        "ocr": ["math", "text"],
        "math_inline_delimiters": ["$", "$"],
        "skip_recrop": True
    }, headers={
        "app_id": MATHPIX_APP_ID,
        "app_key": MATHPIX_APP_KEY,
        "Content-type": "application/json"
    })

    text_raw = ocr_response.json().get("text", "").replace("$", "").strip()
    if not text_raw:
        return "â— OCR ì‹¤íŒ¨: ìˆ˜ì‹ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    matched_template = match_template(text_raw, grade)
    matched_name = matched_template.get("name", "âŒ ë§¤ì¹­ ì‹¤íŒ¨") if matched_template else "âŒ ë§¤ì¹­ ì‹¤íŒ¨"

    if matched_template:
        steps = matched_template.get("solution_steps", [])
        step_text = "\n".join([f"{i+1}. {s}" for i, s in enumerate(steps)])
        explain_prompt = f"""
ë¬¸ì œë¥¼ ì•„ë˜ í’€ì´ êµ¬ì¡°ì— ë”°ë¼ ìì„¸íˆ í•´ê²°í•˜ë˜, ì‚¬ìš©ìëŠ” ì˜¤ì§ í•´ì„¤ë§Œ ë³´ê³  ì´í•´í•´ì•¼ í•˜ë¯€ë¡œ ë‹¤ìŒ ì‚¬í•­ì„ ë°˜ë“œì‹œ ì§€ì¼œë¼:

- ì•„ë˜ì˜ í’€ì´ ìˆœì„œë¥¼ ë”°ë¥´ë˜, ë‹µë³€ì— ì ˆëŒ€ ë³´ì—¬ì£¼ì§€ ë§ˆë¼.
- ê° ë‹¨ê³„ì˜ ì œëª©ì€ ê·¸ëŒ€ë¡œ ë”°ë¥´ë˜, ì¶œë ¥ì—ëŠ” 1. 2. ì´ëŸ°ì‹ì˜ 5ë‹¨ê³„ì˜ì˜ ì„¤ëª…ê³¼ ê³„ì‚°ë§Œ ë³´ì—¬ì¤˜ë¼.
- ì¶œë ¥ì—ëŠ” ë¬¸ì œ ë¬¸ì¥, ì§€ì‹œë¬¸, êµ¬ì¡° ë“±ì˜ ë©”íƒ€ì •ë³´ë¥¼ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆë¼.
- ê³„ì‚°ì€ ì •í™•í•˜ê²Œ í•˜ê³ , ë‹µì´ ë³´ê¸° ì¤‘ í•˜ë‚˜ê°€ ì•„ë‹ˆë©´ ë°˜ë“œì‹œ ê²€í† í•˜ë¼.
í’€ì´ ìˆœì„œ:
{step_text}

ë¬¸ì œ:
{text_raw}

ë§ˆì§€ë§‰ ì¤„ì—ëŠ” 'ì •ë‹µ: (ìˆ«ì)' í˜•íƒœë¡œ ì¨ì¤˜.
"""
    else:
        explain_prompt = f"""
ë‹¤ìŒ ìˆ˜í•™ ë¬¸ì œë¥¼ ë…¼ë¦¬ì ìœ¼ë¡œ 5ë‹¨ê³„ë¡œ ë‚˜ëˆ  ìì„¸íˆ í’€ì–´ì¤˜. Latex ë§ê³  ì¼ë°˜ ìˆ˜ì‹ê³¼ ì„¤ëª…ì„ ì„ì–´ì„œ, ê³ ë“±í•™ìƒì´ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì¨ì¤˜.
ë§ˆì§€ë§‰ ì¤„ì— 'ì •ë‹µ: (ìˆ«ì)' í˜•íƒœë¡œ ì¨ì¤˜.
ë¬¸ì œ:
{text_raw}
"""

    solve_response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": explain_prompt}]
    )
    explanation = solve_response.choices[0].message.content.strip()

    # ì •ë‹µ ì¶”ì¶œ
    lines = explanation.splitlines()
    last_line = lines[-1]
    answer_match = re.search(r'ì •ë‹µ:\s*\(?(\d+)', last_line)
    final_answer = answer_match.group(1) if answer_match else "?"

    # ê·¸ë˜í”„ ì½”ë“œ ìƒì„± (ì—ëŸ¬ ë°œìƒ ì‹œ ë¬´ì‹œ)
    graph_prompt = f"""
ë‹¤ìŒ ìˆ˜í•™ í•¨ìˆ˜(ë˜ëŠ” êµ¬ê°„ë³„ í•¨ìˆ˜)ì˜ ê·¸ë˜í”„ë¥¼ matplotlib ì½”ë“œë¡œ ê·¸ë ¤ì¤˜.
ì¡°ê±´:
- np.linspace ì‚¬ìš©
- ì¡°ê±´ë¶€ í•¨ìˆ˜ë©´ êµ¬ê°„ì„ ë‚˜ëˆ  ê°ê° plot
- xì¶•ê³¼ yì¶• ë¼ë²¨ ì¶”ê°€
- plt.savefig('graph_output.png') ìœ¼ë¡œ ì €ì¥
- plt.show() í•˜ì§€ ë§ê³  ì €ì¥ë§Œ
- ì½”ë“œ ì™¸ í…ìŠ¤íŠ¸ ì—†ì´ ìˆœìˆ˜ Python ì½”ë“œë§Œ ì¤˜
ìˆ˜ì‹:
{text_raw}
"""
    graph_response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": graph_prompt}]
    )
    code_block = re.findall(r"```python(.*?)```", graph_response.choices[0].message.content, re.DOTALL)
    if code_block:
        try:
            exec(code_block[0], {"np": np, "plt": plt})
        except Exception as e:
            explanation += f"\n\n[âš ï¸ ê·¸ë˜í”„ ì½”ë“œ ì‹¤í–‰ ì‹¤íŒ¨: {e}]"

    # í•´ì„¤ ë³¸ë¬¸ (ë§ˆì§€ë§‰ ì •ë‹µ ì¤„ ì œì™¸)
    body = "\n".join(lines[:-1]) if len(lines) > 1 else explanation

    # âœ… ìµœì¢… ì¶œë ¥ í¬ë§·
    return (
        #f"[ğŸ§  OCR ê²°ê³¼]\n{text_raw}\n\n"
        #f"[ğŸ§© í…œí”Œë¦¿ ë§¤ì¹­]\n{matched_name}\n\n"
        f"[ğŸ§¾ 5ë‹¨ê³„ í•´ì„¤]\n{body.strip()}\n\n"
        f"[ğŸ¯ ìµœì¢… ì •ë‹µ]\n{final_answer}"
    )


#ì¶”ì²œë¬¸ì œìƒì„± (GPTê¸°ë°˜)
def recommend_problems_with_gpt(user_id: str, solve_log_path: str) -> list:
    with open(solve_log_path, "r", encoding="utf-8") as f:
        log = json.load(f)

    user_log = log.get(user_id)
    if not user_log:
        return "[]"

    entries = []
    for date, problems in user_log.items():
        for p in problems:
            q = p.get("question", "")[:80].replace("\n", " ")
            ua = p.get("user_answer", "")
            ca = p.get("correct_answer", "")
            status = "ë§ìŒ" if ua == ca else "í‹€ë¦¼"
            entries.append(f"- Q: {q} / ì‚¬ìš©ìì˜ ë‹µ: {ua} / ì •ë‹µ: {ca} â†’ {status}")

    prompt = (
    "ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ìˆ˜í•™ ë¬¸ì œ í’€ì´ ê¸°ë¡ì…ë‹ˆë‹¤. ë§ì´ í‹€ë¦° ë‹¨ì›ì„ ë°”íƒ•ìœ¼ë¡œ "
    "**ë‹¨ì›ëª…(unit), ë‚œì´ë„(difficulty), ë¬¸ì œ(question)** ì •ë³´ë¥¼ í¬í•¨í•œ "
    "**JSON ë¦¬ìŠ¤íŠ¸ í˜•ì‹**ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”. ì„¤ëª… ì—†ì´ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n\n"
    + "\n".join(entries[-20:])
)
    print("ğŸ“¦ GPT PROMPT:\n", prompt) 

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7,
    )
    print("ğŸ“¦ GPT RESPONSE:\n", response.choices[0].message.content) 
    try:
        return json.loads(response.choices[0].message.content)
    except json.JSONDecodeError:
        return []
